{"docstore/metadata": {"113d859c-7b19-480e-8e95-148a7090b01b": {"doc_hash": "9e921ca1f718a9ff0011023cd4f44ccd9ff7fc72d0bdfe511ab35b30e946cd90"}, "e2617c54-dd62-4e60-96cb-a964afcc2dbc": {"doc_hash": "517586d861f5b4317f908798da606a670899c14b8215583aa5096a8f36774452"}, "7a770902-a0ad-4e63-ae68-8069eebf47c9": {"doc_hash": "d9a56cd7d50350cc1385310b94d0b89575a6ebd60d18d917779f04d9e7edfd89"}, "eb1c0c5c-a926-4f6c-9dfd-739228c2798b": {"doc_hash": "e0957ca0830f350f75b454e40c1b57c09d3d8ed576fe97485804d4e0e6a927ae"}, "173b08c9-efc5-4e90-b1c4-c3d300f82aff": {"doc_hash": "ae7d75718b102921fa89867f2977eb167bffcaff8a40d338c23cb40ff8e9df60"}, "8bf9cdfc-e749-4418-a13d-470f7d29a170": {"doc_hash": "f44773513c681f8a04f7a92fb15b8275aeeb33e061c311ec5cd0be7ccc792730"}, "03e1518a-27aa-4653-ac2d-fce25c0294dc": {"doc_hash": "568db35f1e5f51e2f8cd17fef677b3b57cc9be28a80bdf591033b3d27776c316"}, "b3b5872c-3035-40f5-92ee-fbf1fa9d69b3": {"doc_hash": "50936fb0d580d3f47ea618453dd276d6293f485a95c8e291f4c41b772dcd08ef"}, "fc6c4ef0-c16f-44de-a7e2-0c9d8922c0e0": {"doc_hash": "0d4d8a4373a6a114b3c1f77cbb4516c094b9ffe28aa5db714ae8c11c205ef367"}, "aec49d9b-ea7c-4a44-9ec5-20051a35b43b": {"doc_hash": "df2176fdd1115421ca2905b60ba316bae5660fbcd65531c6b86d809248b162e7"}, "8b388deb-fdf9-480d-8147-25fb6e5828c1": {"doc_hash": "cc1f2c6ef5f14c5586e249e71162fb8697f63b55aa35efd61a888d713549aa9d"}, "4d6d0734-72fb-4693-9a7d-78079c6643e6": {"doc_hash": "e101ac6e22262cb5e6833fce2df36880c4f0507773267b11e8eae6d5e02f8660"}, "85d27264-687d-460a-adb0-dd6f0781c454": {"doc_hash": "09b64e8b9ac1f2c459b5b5e1ac280ba418d6231347543ce443ff94ab13747a16"}, "ec723f7f-cbfb-4830-b03d-8c454f2880a7": {"doc_hash": "14ec18202c4ab5114d3c70303b78677a2adbcf852cf293df6a1d9bba789729bc", "ref_doc_id": "113d859c-7b19-480e-8e95-148a7090b01b"}, "a0e1ff0f-7682-449c-a80a-649c254c97e0": {"doc_hash": "16fc2be8b9cf90ecce6ebd3686798cae2a017217bf03dccc15deffa842be4301", "ref_doc_id": "e2617c54-dd62-4e60-96cb-a964afcc2dbc"}, "aa332d5d-9b5d-4093-aa70-4b266b0ac4cf": {"doc_hash": "5e4694891ff464f63927e86acb09c1c87dbfa59a68539f31c9fdffb7aacf09d0", "ref_doc_id": "7a770902-a0ad-4e63-ae68-8069eebf47c9"}, "0f645a0a-379c-4128-baa8-9f41588ae884": {"doc_hash": "50740bc82312b8ba890361638f5d1f1813308982a70a2f1e720d17580c2e5079", "ref_doc_id": "eb1c0c5c-a926-4f6c-9dfd-739228c2798b"}, "f36c06e1-f78f-46ba-bf49-d23b9052ca65": {"doc_hash": "06b09192a088d9cedc02f2c827c9638956eec37a3e17fc626cf2350cd3aa91a2", "ref_doc_id": "173b08c9-efc5-4e90-b1c4-c3d300f82aff"}, "5db70fa1-dd2c-4205-bc83-f78ec29dc7bf": {"doc_hash": "0af8dda2c919952dd24f35569a9d398285a3b0eab1a0d7c3b02f6746842e7caf", "ref_doc_id": "8bf9cdfc-e749-4418-a13d-470f7d29a170"}, "ecd5dd15-c91e-43d4-a88d-d1df957b2be3": {"doc_hash": "32cb02a6f5e4216d2b79954967894a915b5ae99fa2023e30183a0522af2f1255", "ref_doc_id": "03e1518a-27aa-4653-ac2d-fce25c0294dc"}, "1be9e96a-3aa8-4950-b1a8-36fe007101ca": {"doc_hash": "b9d0d8f2a9483953f243bb75329940762b08b1d1deeaef493965174fb4f95e9c", "ref_doc_id": "b3b5872c-3035-40f5-92ee-fbf1fa9d69b3"}, "ef89a742-72d4-4a51-8c15-35b1a6b12596": {"doc_hash": "8ec5f8e59f21502846948808c4fc1672358981cc75d763fc209e84d817309b21", "ref_doc_id": "fc6c4ef0-c16f-44de-a7e2-0c9d8922c0e0"}, "32e0634b-76f5-4f32-afe3-16c8921ca513": {"doc_hash": "6b63717c3c7aa1faf7229ac38ef39d9d526263fb75a9580d4c22185eb9a824fc", "ref_doc_id": "aec49d9b-ea7c-4a44-9ec5-20051a35b43b"}, "cc2e9f9d-26cf-4c0a-b03f-484687809c18": {"doc_hash": "11aced9f23288f8238df338322cf78a2c79f6ef38510618b64c1a78cc82503f2", "ref_doc_id": "8b388deb-fdf9-480d-8147-25fb6e5828c1"}, "1e1a7fe2-9be2-4402-9ee9-9dc39bb72bee": {"doc_hash": "f9ef795ba9589781ddc15997fa6fd48d571da34f8a3761bae8a49cc111cc5ebf", "ref_doc_id": "4d6d0734-72fb-4693-9a7d-78079c6643e6"}, "54784df3-e50a-4810-9d5f-9af94f3132b1": {"doc_hash": "8f1a34767803973720b706d2d855dcd2bb1f334b888cf7c1a4a87d2bc7f6c887", "ref_doc_id": "85d27264-687d-460a-adb0-dd6f0781c454"}}, "docstore/ref_doc_info": {"113d859c-7b19-480e-8e95-148a7090b01b": {"node_ids": ["ec723f7f-cbfb-4830-b03d-8c454f2880a7"], "metadata": {}}, "e2617c54-dd62-4e60-96cb-a964afcc2dbc": {"node_ids": ["a0e1ff0f-7682-449c-a80a-649c254c97e0"], "metadata": {}}, "7a770902-a0ad-4e63-ae68-8069eebf47c9": {"node_ids": ["aa332d5d-9b5d-4093-aa70-4b266b0ac4cf"], "metadata": {}}, "eb1c0c5c-a926-4f6c-9dfd-739228c2798b": {"node_ids": ["0f645a0a-379c-4128-baa8-9f41588ae884"], "metadata": {}}, "173b08c9-efc5-4e90-b1c4-c3d300f82aff": {"node_ids": ["f36c06e1-f78f-46ba-bf49-d23b9052ca65"], "metadata": {}}, "8bf9cdfc-e749-4418-a13d-470f7d29a170": {"node_ids": ["5db70fa1-dd2c-4205-bc83-f78ec29dc7bf"], "metadata": {}}, "03e1518a-27aa-4653-ac2d-fce25c0294dc": {"node_ids": ["ecd5dd15-c91e-43d4-a88d-d1df957b2be3"], "metadata": {}}, "b3b5872c-3035-40f5-92ee-fbf1fa9d69b3": {"node_ids": ["1be9e96a-3aa8-4950-b1a8-36fe007101ca"], "metadata": {}}, "fc6c4ef0-c16f-44de-a7e2-0c9d8922c0e0": {"node_ids": ["ef89a742-72d4-4a51-8c15-35b1a6b12596"], "metadata": {}}, "aec49d9b-ea7c-4a44-9ec5-20051a35b43b": {"node_ids": ["32e0634b-76f5-4f32-afe3-16c8921ca513"], "metadata": {}}, "8b388deb-fdf9-480d-8147-25fb6e5828c1": {"node_ids": ["cc2e9f9d-26cf-4c0a-b03f-484687809c18"], "metadata": {}}, "4d6d0734-72fb-4693-9a7d-78079c6643e6": {"node_ids": ["1e1a7fe2-9be2-4402-9ee9-9dc39bb72bee"], "metadata": {}}, "85d27264-687d-460a-adb0-dd6f0781c454": {"node_ids": ["54784df3-e50a-4810-9d5f-9af94f3132b1"], "metadata": {}}}, "docstore/data": {"ec723f7f-cbfb-4830-b03d-8c454f2880a7": {"__data__": {"id_": "ec723f7f-cbfb-4830-b03d-8c454f2880a7", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "113d859c-7b19-480e-8e95-148a7090b01b", "node_type": "4", "metadata": {}, "hash": "9e921ca1f718a9ff0011023cd4f44ccd9ff7fc72d0bdfe511ab35b30e946cd90", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Shaping Agentic AI with\n  Responsible AI and\n  Governance\n\n\n4", "mimetype": "text/plain", "start_char_idx": 2, "end_char_idx": 63, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a0e1ff0f-7682-449c-a80a-649c254c97e0": {"__data__": {"id_": "a0e1ff0f-7682-449c-a80a-649c254c97e0", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e2617c54-dd62-4e60-96cb-a964afcc2dbc", "node_type": "4", "metadata": {}, "hash": "517586d861f5b4317f908798da606a670899c14b8215583aa5096a8f36774452", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Overview\n\nArtificial Intelligence (AI) is progressing beyond narrow task-based applications as systems demonstrate\ngrowing autonomy. Understanding the distinctions between AI Agents and Agentic AI systems is essential.\n\nAI Agents are task-focused tools that operate within structured workflows with limited independence,\nsuch as chatbots or recommendation engines. Agentic AI Systems exhibit higher levels of adaptability,\nenabling either collaborative operation among multiple agents or independent decision-making in\nsystems like self-driving vehicles, all within predefined boundaries. The concept of Agentic AI refers to\nsystems demonstrating goal-oriented, self-initiating behaviors.\n\n\nOpportunities, challenges and strategic governance\n\nThis paper provides HCLTech\u2019s point of view on the opportunities, challenges and governance frameworks\nrequired for responsible Agentic AI. We examine industry specific applications, operational risks and\nnecessary ethical safeguards. Our recommendations are aimed at leaders, policymakers and practitioners\nalike, to inspire collaboration and promote innovation while maintaining accountability and reducing\npotential negative societal impacts.\n\n\n1  Introduction to AI Agents and Agentic AI\n\n\nDefinition\n\n     AI Agents perceive their environment and can act autonomously to achieve goals. These agents range from simple\n     bots to complex task executors.\n\n     Agentic AI signifies systems with high autonomy and agency, capable of independent decision-making, action and\n     learning with minimal human input. Agentic AI systems represent an evolution from Robotic process automation\n     (RPA), traditional Machine learning (ML)/Deep learning (DL)/Natural language processing (NLP)-based automation\n     and Generative AI (GenAI). While GenAI focuses on content creation, Agentic AI emphasizes autonomy and\n     adaptability.\n\nEvolution of Autonomy\nAs automation processes evolve, the need for Responsible AI and Governance in automated systems increases.\n\n\u2022     RPA: Scripted automation (e.g., invoice processing)\n\n\u2022     ML/NLP: Smarter tools (e.g., sentiment-aware chatbots)\n\n\u2022     GenAI: Creative problem-solving (e.g., generating marketing content)\n\n\u2022     Agentic AI: Goal-aligned; emphasizes deliberation, multi-step decision making and reasoning toward specific\n      objectives. (e.g., managing global logistics or autonomous vehicle systems)", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 2400, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "aa332d5d-9b5d-4093-aa70-4b266b0ac4cf": {"__data__": {"id_": "aa332d5d-9b5d-4093-aa70-4b266b0ac4cf", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7a770902-a0ad-4e63-ae68-8069eebf47c9", "node_type": "4", "metadata": {}, "hash": "d9a56cd7d50350cc1385310b94d0b89575a6ebd60d18d917779f04d9e7edfd89", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Differences between AI Agents and Agentic AI\n\n\nAI Agent\nTask-oriented            Standard AI Agents are task-specific, following\nLimited independence     predefined rules within narrow scopes.\nStructured workflows\nPredefined objectives\n\n\nAgentic AI                         Agentic AI is a broader, autonomous framework for\nGoal-driven intentionality         dynamic planning and problem-solving across contexts.\nStrategic reasoning                It reasons, adapts, directs multiple agents and operates\nAdvanced planning capabilities     with higher agency in dynamic environments.\nReflective/adaptive behaviours\n\n\nAspect              AI Agents                                     Agentic AI\n\nScope of Goals      Narrow, single-domain tasks                   Complex, multi-step goals across domains\n\nAutonomy            Limited; executes predefined instructions     High; makes decisions with minimal oversight\n\nDecision-Making     Reactive; rule-based or prompted              Proactive; plans, reasons, learns continuously\n\nExamples            Email sorter, scheduling bot, FAQ bot         Self-driving car, workflow manager, smart home system\n\nRelationship        Building blocks for specific functions        Overall framework coordinating multiple agents\n\n\n What is a Responsible\n AI agent?\n\nResponsible AI Agent\nAdheres to ethical principles, safety and\naccountability. Its operations are\ntransparent, fair, unbiased, secure,\nprivacy-respecting and aligned with human\nvalues (example: an AI hiring tool actively\ndesigned to mitigate bias). As AI systems\nevolve into Agentic AI, responsible principles\nstill hold true and are vital in the\ndevelopment of trustworthy Agentic AI\nsystems.", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 1693, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0f645a0a-379c-4128-baa8-9f41588ae884": {"__data__": {"id_": "0f645a0a-379c-4128-baa8-9f41588ae884", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "eb1c0c5c-a926-4f6c-9dfd-739228c2798b", "node_type": "4", "metadata": {}, "hash": "e0957ca0830f350f75b454e40c1b57c09d3d8ed576fe97485804d4e0e6a927ae", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Key metrics for Responsible AI-enabled, scaled adoption\n\nArea                           Metrics & Approach\n\nFairness                       Minimizing bias against protected groups\n                               (demographic parity, equal opportunity, equalized odds).\n\nSafety &                       Enabling resilience to adversarial inputs\nrobustness                     (Adversarial Robustness) and minimizing\n                               unintended negative side-effects.\n\nAccountability &               Logging and auditing every decision\ntraceability                   (action trace completeness).\n\nInterpretability &             Enabling explanations that match model\nexplainability                 behavior (fidelity of explanations).\n\nReliability                    Monitoring calibration so the system\u2019s\n                               confidence aligns with real outcomes.\n\nPrivacy                        Protecting individual information\n                               (differential privacy).\n\nEthical alignment              Verifying adherence to moral and legal\n                               frameworks (policy compliance rate).\n\nCumulative reward              Evaluating how effective the agent is at achieving\n                               long-term objectives while considering\n                               compounding benefits of early favorable actions.\n\nHarm propagation index         Quantifing how errors or undesirable effects propagate\n                               and magnify due to compounding actions.\n\nEfficiency scaling factor      Measuring how the efficiency of the system scales as\n                               compounding effects increase its workload or complexity.\n\n                               Tracking whether an agent\u2019s actions lead to exponentially\nCompounding rate impact        increasing or stabilizing impacts. Useful for systems like\n                               autonomous trading bots or social media content algorithms.\n\n                               Identifing whether feedback loops amplify\nAmplification co-efficient     errors or improvements. Example: In recommendation\n                               systems, it assesses how recommendations influence user\n                               behavior, creating self-reinforcing loops.\n\nEmergent behavior index        Quantifing the degree to which new, unplanned behaviors\n                               emerge due to compounding effects within the system.\n\n                               Measuring how changes in agent policies lead to cascading\nPolicy cascading impact        effects across interconnected systems. E.g.; How\n                               cross-system policy changes in multi-agent or complex\n                               environments, such as smart cities or supply chains.\n\nLong-term outcome drift        Measuring divergence between intended and actual\n                               long-term outcomes due to compounding effects.", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 2967, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f36c06e1-f78f-46ba-bf49-d23b9052ca65": {"__data__": {"id_": "f36c06e1-f78f-46ba-bf49-d23b9052ca65", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173b08c9-efc5-4e90-b1c4-c3d300f82aff", "node_type": "4", "metadata": {}, "hash": "ae7d75718b102921fa89867f2977eb167bffcaff8a40d338c23cb40ff8e9df60", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2 Responsible AI Opportunities\n\n Opportunities across industries:\n How Responsible AI improves use cases\n\n Companies leading in Responsible AI report tangible benefits like better products, increased profitability and\n improved talent attraction. Real-world value often stems from deep integration of Responsible AI principles into\n business processes and systems. Agent-Human collaboration often yields better results over pure Agent-Agent or\n Agent-Environment interactions.\n\n There is significant potential for hyper-personalized experiences, especially in the retail industry. Opportunities\n also exist in customer service (improving satisfaction with accurate, autonomous support) and healthcare\n (monitoring patient data ethically).\n\n\n Other key sector-related opportunities include:\n HR efficiency: Enhance fairness     Customer support Elevate:      Supply chain and logistics:\n and efficiency in hiring,           Elevate agentic knowledge      Real-time optimization\n onboarding and employee             assistants to deliver more     enhances efficiency and\nE                                    accurate, contextual and       reduces waste, with\n development through\n responsible automation              ethical service.               Responsible AI fostering safety.\n Financial services: Portfolio       Cross-department insight: Use\n management, fraud detection         AI responsibly to surface\n and advice benefit from             actionable insights without\n Responsible AI promoting            compromising data integrity or\n fairness (unbiased lending) and     compliance.\n transparency.\n\n How Responsible AI unlocks new opportunities\n Embedding Responsible AI unlocks new opportunities across business functions by enabling more advanced,\n trustworthy applications. For instance, sales teams can benefit from automated lead qualification and\n personalized content creation, while HR departments can streamline candidate screening, onboarding and\n employee training.\n\n Responsible AI also expands the capabilities of knowledge support agents, paving the way for more adaptive,\n compliant and human-aligned AI applications. Departments can streamline candidate screening, onboarding\n and employee training.", "mimetype": "text/plain", "start_char_idx": 2, "end_char_idx": 2225, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5db70fa1-dd2c-4205-bc83-f78ec29dc7bf": {"__data__": {"id_": "5db70fa1-dd2c-4205-bc83-f78ec29dc7bf", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8bf9cdfc-e749-4418-a13d-470f7d29a170", "node_type": "4", "metadata": {}, "hash": "f44773513c681f8a04f7a92fb15b8275aeeb33e061c311ec5cd0be7ccc792730", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Technology design choices\nimpacting Responsible AI\n\nResponsible AI starts at the design\nstage. Deliberate technology\ndesign choices influence the              Transparency\ntrustworthiness, safety and               & Traceability\naccountability of AI systems. These\ndecisions establish the AI models\nto be not only efficient, but also\naligned with transparency, fairness                     System\nand ethical expectations. Effective\nResponsible AI design emphasizes:                       Design\n\n Safety & bias mitigation:\n Integrating bias mitigation tools,\n ethical red-teaming, content filters,    Technology\n privacy and responsible-by-design.\n\n System design: Addressing                Design        Sustainability\n memory management, utilizing             Choices       & Efficiency\n appropriate design patterns,\n enabling adaptive learning,\n ensuring scalability\n (distributed/edge                        Safety &\n computing), prioritizing\n explainability and robust                Bias Mitigation\n monitoring (drift detection,\n anomaly management).\n\n Transparency & traceability:\n Enabling explainability, logging\n and auditability to demystify\n how decisions are made.\n\n Sustainability & efficiency:\n Optimizing models and code\n for lower environmental and\n operational costs.", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 1287, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ecd5dd15-c91e-43d4-a88d-d1df957b2be3": {"__data__": {"id_": "ecd5dd15-c91e-43d4-a88d-d1df957b2be3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "03e1518a-27aa-4653-ac2d-fce25c0294dc", "node_type": "4", "metadata": {}, "hash": "568db35f1e5f51e2f8cd17fef677b3b57cc9be28a80bdf591033b3d27776c316", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3 Risks and Challenges\n\n      General industry challenges\n       Across industries, organizations face a range of systemic challenges that complicate the responsible scaling\n       of AI and intelligent systems. Beyond the persistent shortage of high-quality, compliant data, issues such as\n       legacy infrastructure, regulatory uncertainty, operational silos and skill gaps also create significant hurdles.\n\n      Risks particular to Agentic AI\n      Agentic systems can introduce unique risks particular to AI. Goal misalignment is a key concern, where\n      agents might exploit loopholes or overlook unmeasurable ethical factors while pursuing literal, measurable\n      goals. The compounded impact of small errors can lead to large deviations, particularly in areas like finan ce\n      or adversarial cyberattacks.\n\n\n                               Agentic AI risks\n\n    Goal                                       Compounded\n    Misalignment                               Impact\n    AI\u2019s objectives diverge                    AI actions lead to\n    from human intentions                      unforseen consequences\n\nRoot Cause                                     Workforce\nComplexity                                     Displacement\n    Difficulty in tracing                      AI replaces human jobs\n    AI-related issues\n\n                          Human\n    Disempowerment\n            AI diminishes human\n    control and agency\n\n\n    Industry specific challenges include:\n\n    1.     Healthcare: Patient data is siloed across providers and often subject to strict regulations like HIPAA, limiting AI\n           training on diverse populations and edge cases.\n\n    2.     Retail and ecommerce: Incomplete or biased customer data skews personalization algorithms, leading to\n           ineffective or exclusionary recommendations.\n\n    3.     Finance: Legacy systems generate fragmented and non-standardized data, undermining AI-driven credit\n           scoring, fraud detection and regulatory reporting.\n\n    4.     Manufacturing: Inconsistent sensor and maintenance data hinders predictive maintenance models and\n           optimization of production lines.\n\n    5.     Public Sector: Limited access to high-fidelity public records and citizen data reduces the effectivenes\n           of AI in social services, policy forecasting and fraud prevention.\n    .", "mimetype": "text/plain", "start_char_idx": 5, "end_char_idx": 2373, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1be9e96a-3aa8-4950-b1a8-36fe007101ca": {"__data__": {"id_": "1be9e96a-3aa8-4950-b1a8-36fe007101ca", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b3b5872c-3035-40f5-92ee-fbf1fa9d69b3", "node_type": "4", "metadata": {}, "hash": "50936fb0d580d3f47ea618453dd276d6293f485a95c8e291f4c41b772dcd08ef", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These challenges are compounded by the rapid rise of Low-Code/No-Code (LCNC) platforms, which, while\naccelerating development, can also introduce risks around unchecked agent proliferation, inconsistent quality\nassurance and weakened security protocols. This is particularly true in scenarios where 'Bring Your Own AI'\npractices could lead to Shadow AI deployments outside formal governance frameworks. For example, see the\nscenario below:\n\n               EFFICIENCY\n\n\n            An operations team deploys an open-source                      Over time, the system begins to optimizing for cost\n            Ai Agent to automate procurement, handling vendor              and speed. Adapting on its own by bypassing vendor\n            selection, bid comparrison and routine ordering.               policies and approval chains. Initially, efficiency improves.\n\n  Soon after: The Ai Agent favors unvetted vendors with\n  lower prices, ignoring compliance and risk guidelines. It\n  silently circumvents internal review processes.\n\n            OPTIMIZE\n\n                                                                                                                  CONTRACT\n\n    VENDOR\n  CHECKLIST\n\n                                                                                                                                55\n                        POLIcy                                              A major contract is awarded to blacklisted supplier,\n                                                                            triggering regulatory and reputational fallout.\n                                                                                                                  BLOCKLISTED\n\n            GUARDRAILS              RAI PRACTICES                           RAI TRAINING COMPLETE\n                                           TENETS\n\n                                                                                                                           DO\n\n            0\n                                                           GOVERNANCE\n                                                           AUDIT\n During a governance audit, they found that the AI acted with             The company established a Responsible AI and Governance\n agency. Learning, adapting and executing with minimal oversight,         CEO in their operation, with human-in-the-loop and Agentic\n it made optimized but policy-violating decisions beyond its original     process review. These changes led to greater process optimization\n  scope.                                                                  and ROI, as well as company-wide growth.\n\nAdditional specific risks include:\n\nRoot cause identification complexity: Modern systems often involve numerous interconnected\ncomponents and processes. A fault in one area can propagate through the system, making it challenging\nto isolate the original cause. This complexity is further compounded by the vast amount of data generated,\nwhich can be overwhelming and obscure the true source of a problem. When issues arise, it can be unclear\nwho is responsible, complicating governance and oversight.\n\nWorkforce displacement: Broad automation potential requiring societal transition management and\nreskilling.\n\nHuman disempowerment and psychological effects: Risks from over-reliance, skill atrophy, automation\nbias, stress and loss of autonomy.", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 3397, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ef89a742-72d4-4a51-8c15-35b1a6b12596": {"__data__": {"id_": "ef89a742-72d4-4a51-8c15-35b1a6b12596", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fc6c4ef0-c16f-44de-a7e2-0c9d8922c0e0", "node_type": "4", "metadata": {}, "hash": "0d4d8a4373a6a114b3c1f77cbb4516c094b9ffe28aa5db714ae8c11c205ef367", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4 Guardrail Framework for Addressing Risks\n\n  A multilayered guardrail framework, often characterized by user centricity, transparency and robust\n  guardrails, is essential to manage AI risks effectively. This framework incorporates foundational,\n  risk-based and societal levels.\n\n  Foundational guardrails\n\n  Foundational guardrails represent the                Key components include:\n  baseline, non-negotiable rules that                  Baseline evaluations:\n  are applicable to all AI systems, enabling           Implementing bias checks before deployment.\n  adherence to core ethical principles and\n  compliance with privacy and security                 Alignment to recognized standards:\n  standards. These processes and technical             Adhering to frameworks like NIST AI, RMF\n  guardrails promote Responsible AI aspects            and ISO 42001.\n  across the board.\n\n  Risk-based guardrails\n\n  Building upon the foundational guardrails,          Further stipulations may involve specific\n  risk-based guardrails apply additional              controls like:\n  controls proportionate to the specific use          Human approval: Restricting actions requiring\n  case risk. Low risk applications may only           direct human approval and providing on-call\n  need minimal guardrails, such as clear user         human operators for intervention.\n  disclaimers or basic monitoring for accuracy.\n  High risk applications will need stricter           Enhanced transparency: Detailed logging and\n  requirements, such as mandatory ethics              monitoring of function calls and input/output.\n  reviews, impact assessments or rigorous\n  testing and validation.\n\n  Societal guardrails\n\n  Societal guardrails operate at the broader          Upskilling and training programs:\n  ecosystem level, protecting against risks           Providing education to adapt to\n  impacting society more broadly. This                AI advancements.\n  includes laws, regulations, standards and\n  norms like formal regulations (e.g., EU AI Act)     Incident reporting mechanisms: Creating systems\n  and sector-specific rules.                          for reporting and responding to AI-related\n  They also encompass:                                incidents.\n  Value alignment: Establishing alignment             Public policy development: Engaging with\n  with societal values.                               policymakers to shape Responsible AI use.\n\n                                 Enabling Agentic Growth\n\nAgentic AI will touch nearly every part of an organization and the people it serves. Everyone has a role to play in\nensuring its responsible use. Enterprise and legal professionals should start conversations early about\naccountability, documentation and compliance. The conversations should include privacy and risk teams in AI\n  projects from the outset when needed. They can create processes that can adapt as laws and technologies\nevolve. Technology and product teams should build explainability and safety into systems from the beginning.\n\nThese teams should enable provenance and monitoring mechanisms and collaborate across departments\n  to avoid silos and blind spots. Regulators and policymakers should explore risk-based and use-case-specific\nrules that support innovation and protect people. They should continue to encourage transparency, training\nand international alignment.", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 3390, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "32e0634b-76f5-4f32-afe3-16c8921ca513": {"__data__": {"id_": "32e0634b-76f5-4f32-afe3-16c8921ca513", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "aec49d9b-ea7c-4a44-9ec5-20051a35b43b", "node_type": "4", "metadata": {}, "hash": "df2176fdd1115421ca2905b60ba316bae5660fbcd65531c6b86d809248b162e7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "5 Guardrails Within an Organization\n\n Effective internal governance relies on key organizational\n controls, including establishing governance bodies\n (for example, an AI Ethics Committee) and setting clear\n policies (risk management, codes of conduct, data rules).\n Comprehensive training programs are also vital for enabling\n the organization with responsibly aware, ethically minded team\n members.\n Other essential elements include:\n         Accountability structures:\n         Dedicated Responsible AI roles\n\n         Monitoring & response:\n         Processes for continuous system\n         monitoring and incident response\n\nComplementing organizational structures are essential\ntechnical mitigations and metrics. These include the\ndeployment of tools for bias detection/mitigation and\ntechniques promoting explainability/transparency. Enabling\nrobustness and safety through methods like adversarial testing\nand fail-safes are also critical.\n\nAdditional technical measures may involve:\n         Performance monitoring:\n         Continuous tracking of accuracy, model/data drift\n         and ethical metrics. A range of metrics may be used,\n         covering fairness, safety, robustness, accountability,\n         traceability, privacy, ethical alignment and potential\n         compounding impacts like long-term drift\n\n6 Recommendations for\n  executives and policymakers\n\n  A recent report from HCLTech in\n  partnership with MIT reveals that while\n  87% of executives recognize the\n  importance of Responsible AI, only\n  15% feel fully prepared to implement it.\n  With the increasing pace of Agentic AI\n  development, it\u2019s imperative for businesses\n  to figure out how to effectively integrate\n  Responsible AI and governance into\n  their operations.\n\n  One of the most pervasive misconceptions\n  surrounding Responsible AI is the\n  tendency to focus primarily on long-term,\n  large-scale risks, such as the impact\n  on jobs and ways of working. However,\n  organizations often overlook more\n  immediate and actionable measures\n  that can mitigate risks in the short-term\n  like those outlined below:", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 2103, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cc2e9f9d-26cf-4c0a-b03f-484687809c18": {"__data__": {"id_": "cc2e9f9d-26cf-4c0a-b03f-484687809c18", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8b388deb-fdf9-480d-8147-25fb6e5828c1", "node_type": "4", "metadata": {}, "hash": "cc1f2c6ef5f14c5586e249e71162fb8697f63b55aa35efd61a888d713549aa9d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "NV\n\n\nCONTRACT\n\n\n                                                                         BLACKLISTED\nWM\nFor executives & business leaders:          For policymakers and regulators:\n\nPrioritize Responsible AI strategically:     Adopt risk-based regulation:\nMake Responsible AI a core element           Focus strict rules on high-risk AI\nof the organization\u2019s strategy;              and allow flexibility for low-risk uses.\nallocate resources; enable\nC-suite ownership.\n                                             Establish clear standards:\n\nEstablish robust governance:                 Develop benchmarks for fairness,\nImplement internal guardrails                transparency, robustness via\n(boards, policies, roles); integrate         collaboration and engagement with\nwith enterprise risk; increase               industry experts.\nboard oversight.\n                                             Increase oversight & accountability:\nInvest in talent & training:                 Clarify liability; enhance regulatory\nBuild technical and ethical expertise;       capacity; require record-keeping;\nfoster diverse teams; provide                empower consumers.\nongoing education.\n\n                                             Promote transparency &\nEmbed guardrails                             information sharing:\nacross lifecycle:                            Encourage and mandate\nIntegrate Responsible AI                     disclosure, labeling; foster\nstarting from ideation to                    international cooperation.\nmaintenance; reduces failures.\n\n                                             Support responsible innovation:\nLeverage Responsible AI as                   Fund AI safety R&D; use regulatory\ncompetitive advantage:                       sandboxes; invest in education and\nResponsible AI maturity boosts               workforce development; support\nAI value and can build trust.                organizations adopting responsible\n                                             practices.\n\nPlan for human impact:                       Lead by example and engage\nInvest in reskilling; manage                 stakeholders:\ntransitions humanely.                        Enable ethical public sector AI use;\n                                             involve diverse groups in policymaking;\n                                             facilitate industry collaboration.", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 2387, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1e1a7fe2-9be2-4402-9ee9-9dc39bb72bee": {"__data__": {"id_": "1e1a7fe2-9be2-4402-9ee9-9dc39bb72bee", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4d6d0734-72fb-4693-9a7d-78079c6643e6", "node_type": "4", "metadata": {}, "hash": "e101ac6e22262cb5e6833fce2df36880c4f0507773267b11e8eae6d5e02f8660", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "@  Accountability\nTransparency\n            2\n            HCLTech\n   Responsible AI\n            Tenets\n                   Fairness\nPrivacy\n                   3\n\n            Security\n\n\n7 Conclusion\n\nResponsibly harnessing Agentic AI with expert partnership\n\nAgentic AI is no longer a future concept, it\u2019s delivering real impact today. From dynamic supply chain planning\nthat adapts to global disruptions to agentic contract monitoring that safeguards compliance and reduces legal\nrisk, Agentic systems are driving measurable business outcomes across industries. In banking and telecom,\npersonalized customer engagement powered by AI agents is boosting retention and satisfaction. In healthcare\nand hospitality, adaptive workforce scheduling is improving efficiency while promoting fairness.\n\nThese use cases demonstrate not only the transformative potential of Agentic AI but also the importance of\ndeploying it responsibly. HCLTech\u2019s expertise in adopting Responsible AI frameworks reinforce that every\nsolution is aligned with ethical principles, regulatory standards like the EU AI Act, and human values.\n\nPartner with HCLTech to move beyond experimentation toward scalable, secure and ethically grounded Agentic\nAI adoption. Together, we can build a future where autonomous systems are trusted accelerators of progress.", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 1322, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "54784df3-e50a-4810-9d5f-9af94f3132b1": {"__data__": {"id_": "54784df3-e50a-4810-9d5f-9af94f3132b1", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "85d27264-687d-460a-adb0-dd6f0781c454", "node_type": "4", "metadata": {}, "hash": "09b64e8b9ac1f2c459b5b5e1ac280ba418d6231347543ce443ff94ab13747a16", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "About HCLTech\n\nHCLTech is a global technology company, home to more than 223,000 people across 60 countries, delivering\nindustry-leading capabilities centered around digital, engineering, cloud and AI, powered by a broad portfolio\nof technology services and products. We work with clients across all major verticals, providing industry\nsolutions for Financial Services, Manufacturing, Life Sciences and Healthcare, Technology and Services,\nTelecom and Media, Retail and CPG and Public Services. Consolidated revenues as of 12 months ending\nMarch 2025 totaled $13.8 billion. To learn how we can supercharge progress for you, visit hcltech.com.", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 643, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}}